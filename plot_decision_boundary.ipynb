{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d720d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force to use CPU for benchmarking\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if using GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e7454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer as load_data\n",
    "import numpy as np\n",
    "from h3 import h3\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.layers import Dense, Dropout, Embedding, concatenate, Flatten, BatchNormalization, Activation, Discretization\n",
    "from keras import models\n",
    "import keras\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf854b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import clean, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb10fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f38b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nyc-taxi-trip-duration/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e09d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77079009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamp\"] = pd.to_datetime(df[\"pickup_datetime\"])\n",
    "df = df.sort_values(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce71955",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean(df)\n",
    "df, hash_vocab_size, h3_cell_mappings = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f616b4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b82144",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cutoff = df[\"timestamp\"].max() - pd.Timedelta(weeks=4)\n",
    "valid_cutoff = test_cutoff - pd.Timedelta(weeks=2)\n",
    "df_test = df[df[\"timestamp\"] > test_cutoff]\n",
    "df_train = df[df[\"timestamp\"] < valid_cutoff]\n",
    "df_valid = df[df[\"timestamp\"].between(valid_cutoff, test_cutoff)]\n",
    "print(df_train.shape)\n",
    "print(df_valid.shape)\n",
    "print(df_test.shape)\n",
    "h3_resolutions = [4, 5, 6, 7, 8, 9, 10] # Which to actually use for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5b513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb44c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "\"pickup_longitude\",\n",
    "\"pickup_latitude\",\n",
    "\"dropoff_longitude\",\n",
    "\"dropoff_latitude\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[numeric_features]\n",
    "y = (df[\"trip_duration\"] > 600).astype(int)\n",
    "\n",
    "X_train = df_train[numeric_features]\n",
    "y_train = (df_train[\"trip_duration\"] > 600).astype(int)\n",
    "\n",
    "X_valid = df_valid[numeric_features]\n",
    "y_valid = (df_valid[\"trip_duration\"] > 600).astype(int)\n",
    "\n",
    "X_test = df_test[numeric_features]\n",
    "y_test = (df_test[\"trip_duration\"] > 600).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5545a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e58ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_h3 = df_train[[x for x in df.columns if x.startswith(\"h3_hash_index\")]]\n",
    "X_valid_h3 = df_valid[[x for x in df.columns if x.startswith(\"h3_hash_index\")]]\n",
    "X_test_h3 = df_test[[x for x in df.columns if x.startswith(\"h3_hash_index\")]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d851f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb(num_estimators: int, params: dict):\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=num_estimators,\n",
    "                valid_sets=[lgb_train, lgb_eval],\n",
    "                early_stopping_rounds=50)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b987df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e22d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TREE_DEPTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3da0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_binary_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "#     'metric': 'binary', # accuracy\n",
    "    'max_depth': TREE_DEPTH, \n",
    "    'learning_rate': 0.1,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_binary = train_lgb(num_estimators=10000, params=lgb_binary_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773bb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_full_predictions = lgb_binary.predict(X_test, num_iteration=lgb_binary.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e53656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_models import EmbeddedH3Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b618178",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_hyperparams = {\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 100,\n",
    "    \"starting_lr\": 1e-3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b9bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings on h3 cell indices\n",
    "h3_embed = EmbeddedH3Model(h3_resolutions=h3_resolutions, binary=True, hyperparams=nn_hyperparams)\n",
    "h3_embed.train(x_train=X_train_h3, y_train=y_train, x_valid=X_valid_h3, y_valid=y_valid, embedding_vocab_size=hash_vocab_size)\n",
    "h3_embed_pred = h3_embed.predict(X_test_h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0f9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491edd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff04a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_true=y_test, y_pred=lgb_full_predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c348e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_true=y_test, y_pred=h3_embed_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ed579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36228be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplleaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decision_boundary(model, X, xlim=(-74.005, -73.96), ylim=(40.73, 40.78), pickup_lon=None, pickup_lat=None):\n",
    "    # Create a grid for plotting decision boundary. We fix the pickup coordinates to be able to visualise in 2D\n",
    "\n",
    "    if not pickup_lon:\n",
    "        pickup_lon = X[\"pickup_longitude\"].median()\n",
    "    if not pickup_lat:\n",
    "        pickup_lat = X[\"pickup_latitude\"].median()\n",
    "            \n",
    "    X = X.to_numpy()\n",
    "    x_min, x_max = np.percentile(X[:, 0], 0.1), np.percentile(X[:, 0], 99.99)\n",
    "    y_min, y_max = np.percentile(X[:, 1], 0.1), np.percentile(X[:, 1], 99.99)\n",
    "    grid_size = 0.0001\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, grid_size), np.arange(y_min, y_max, grid_size))\n",
    "    xx_ravel = xx.ravel()\n",
    "    yy_ravel = yy.ravel()\n",
    "\n",
    "    pred_array = np.c_[np.repeat(pickup_lon, len(xx_ravel)), np.repeat(pickup_lat, len(yy_ravel)), xx_ravel, yy_ravel]\n",
    "    preds = model.predict(pred_array)\n",
    "    preds = preds.reshape(xx.shape).round()\n",
    "    \n",
    "    return xx, yy, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy, preds = plot_decision_boundary(lgb_binary, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0dac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pickup_lon, pickup_lat, color=\"red\")\n",
    "plt.contourf(xx, yy, preds, alpha=0.4)\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "mplleaflet.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbdb031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c1928e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f029ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_sample = X_test.sample(1).iloc[0]\n",
    "lon_sample = pickup_sample[\"pickup_longitude\"]\n",
    "lat_sample = pickup_sample[\"pickup_latitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_sample, yy_sample, preds_sample = plot_decision_boundary(lgb_binary, X_test, pickup_lon=lon_sample, pickup_lat=lat_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lon_sample, lat_sample, color=\"red\")\n",
    "plt.contourf(xx_sample, yy_sample, preds_sample, alpha=0.4)\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "mplleaflet.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b8ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615e7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5813fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decision_boundary_h3_model(model, X, pickup_lon=None, pickup_lat=None):\n",
    "    \n",
    "    if not pickup_lon:\n",
    "        pickup_lon = X[\"pickup_longitude\"].median()\n",
    "    if not pickup_lat:\n",
    "        pickup_lat = X[\"pickup_latitude\"].median()\n",
    "    \n",
    "    X = X.to_numpy()\n",
    "    x_min, x_max = np.percentile(X[:, 0], 0.1), np.percentile(X[:, 0], 99.99)\n",
    "    y_min, y_max = np.percentile(X[:, 1], 0.1), np.percentile(X[:, 1], 99.99)\n",
    "    grid_size = 0.0001\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, grid_size), np.arange(y_min, y_max, grid_size))\n",
    "    xx_ravel = xx.ravel()\n",
    "    yy_ravel = yy.ravel()\n",
    "    \n",
    "    df_mesh = pd.DataFrame({\"pickup_longitude\": median_pickup_lon, \"pickup_latitude\": median_pickup_lat, \"dropoff_longitude\": xx_ravel, \"dropoff_latitude\": yy_ravel})\n",
    "    \n",
    "    for h3_res in h3_resolutions:\n",
    "        df_mesh[f\"src_h3_{h3_res}\"] = [h3.geo_to_h3(x, y, h3_res) for x, y in\n",
    "                                  zip(df_mesh[\"pickup_latitude\"], df_mesh[\"pickup_longitude\"])]\n",
    "        df_mesh[f\"dst_h3_{h3_res}\"] = [h3.geo_to_h3(x, y, h3_res) for x, y in\n",
    "                                  zip(df_mesh[\"dropoff_latitude\"], df_mesh[\"dropoff_longitude\"])]\n",
    "\n",
    "    h3_cell_tokens = {}\n",
    "    for point in [\"src\", \"dst\"]:\n",
    "        h3_cell_tokens[point] = {}\n",
    "        for h3_res in h3_resolutions:\n",
    "            h3_cell_tokens[point][h3_res] = {}\n",
    "            for i, cell in enumerate(h3_cell_mappings[point][h3_res]):\n",
    "                h3_cell_tokens[point][h3_res][cell] = i\n",
    "            \n",
    "    for point in [\"src\", \"dst\"]:\n",
    "        for h3_res in h3_resolutions:\n",
    "            df_mesh[f\"h3_hash_index_{point}_{h3_res}\"] = [int(h3_cell_tokens[point][h3_res].get(c, -1)) for c in df_mesh[f\"{point}_h3_{h3_res}\"]]\n",
    "    \n",
    "    for point in [\"src\", \"dst\"]:\n",
    "        # We have one unused embedding key to assign to OOV tokens - they'll get randomly initialised embeddings\n",
    "        for h3_res in h3_resolutions:\n",
    "            vocab_size = hash_vocab_size[point][h3_res]\n",
    "            df_mesh[f\"h3_hash_index_{point}_{h3_res}\"] = df_mesh[f\"h3_hash_index_{point}_{h3_res}\"].replace(-1, vocab_size)\n",
    "            \n",
    "    nn_preds = model.predict(df_mesh).round()\n",
    "    nn_preds = nn_preds.reshape(xx.shape)\n",
    "    \n",
    "    return xx, yy, nn_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6162d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy, nn_preds = create_decision_boundary_h3_model(h3_embed, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6002ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pickup_lon, pickup_lat, color=\"red\")\n",
    "plt.contourf(xx, yy, nn_preds, alpha=0.4)\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "mplleaflet.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c8d210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67058181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b156ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
